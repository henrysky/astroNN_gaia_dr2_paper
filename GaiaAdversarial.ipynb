{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This notebook describes the adversial training on dealing with unknown Gaia DR2 offset\n",
    "\n",
    "## Incomplete notebook, work in progress"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First train a NN with Gaia DR2 parallax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from astroNN.models import ApogeeBCNN\n",
    "from astroNN.nn.callbacks import ErrorOnNaN\n",
    "from astroNN.gaia import mag_to_fakemag\n",
    "from astroNN.nn.metrics import mean_absolute_error, mean_error, mean_absolute_percentage_error\n",
    "import h5py\n",
    "import numpy as np\n",
    "\n",
    "with h5py.File('gaia_dr2_train.h5', 'r') as F:  # ensure the file will be cleaned up\n",
    "    spectra = np.array(F['spectra'])\n",
    "    fakemag = np.array(F['fakemag'])  # fakemag from Gaia+0.05mas\n",
    "    fakemag_err = np.array(F['fakemag_err'])\n",
    "    \n",
    "bcnn_net = ApogeeBCNN()\n",
    "bcnn_net.callbacks = ErrorOnNaN()\n",
    "bcnn_net.num_hidden = [192, 96]\n",
    "bcnn_net.max_epochs = 40\n",
    "bcnn_net.metrics = [mean_absolute_error, mean_error, mean_absolute_percentage_error]\n",
    "bcnn_net.autosave = True\n",
    "bcnn_net.train(spectra, fakemag, labels_err=fakemag_err)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Then train a simple n-deg polynomial regression model on parallax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from astroNN.gaia import gaiadr2_parallax\n",
    "from astroNN.models import SimplePolyNN\n",
    "import numpy as np\n",
    "\n",
    "ra, dec, parallax, parallac_err = gaiadr2_parallax(cuts=1., keepdims=False, offset=0.)\n",
    "\n",
    "gaia_nn = SimplePolyNN()\n",
    "gaia_nn.max_epochs = 2\n",
    "gaia_nn.num_hidden = 0  # degree of polynomial\n",
    "gaia_nn.l2 = 0\n",
    "gaia_nn.train( np.atleast_2d(parallax).T, np.atleast_2d(parallax).T)\n",
    "print(\"n-deg poly weights: \", gaia_nn.get_weights()[0][0][0])\n",
    "gaia_nn.save(# model name here)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The adversarial training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================================\n",
      "Loaded astroNN model, model type: Bayesian Convolutional Neural Network -> ApogeeBCNN\n",
      "========================================================\n",
      "========================================================\n",
      "Loaded astroNN model, model type: Convolutional Neural Network -> SimplePolyNN\n",
      "========================================================\n",
      "===========================================\n",
      "Starting Inference\n",
      "Completed Inference, 1.03s elapsed\n",
      "Current Global Offset: -0.0000mas\n",
      "Number of Training Data: 44536, Number of Validation Data: 4948\n",
      "Epoch 1/1\n",
      " - 12s - loss: -2.8568e+00 - output_loss: -2.8569e+00 - variance_output_loss: -2.8569e+00 - output_mean_absolute_error: 0.0529 - output_mean_error: -1.2797e-03 - val_loss: -2.8679e+00 - val_output_loss: -2.8679e+00 - val_variance_output_loss: -2.8679e+00 - val_output_mean_absolute_error: 0.0530 - val_output_mean_error: -1.3587e-02\n",
      "Completed Training, 12.73s in total\n",
      "Starting Dropout Variational Inference\n",
      "Completed Dropout Variational Inference with 10 forward passes, 19.23s elapsed\n",
      "Number of Training Data: 44536, Number of Validation Data: 4948\n",
      "Epoch 1/1\n",
      " - 2s - loss: 0.7862 - mean_absolute_error: 0.1608 - mean_error: 0.0350 - val_loss: 0.5321 - val_mean_absolute_error: 0.1565 - val_mean_error: 0.0245\n",
      "Completed Training, 2.09s in total\n",
      "===========================================\n",
      "Starting Inference\n",
      "Completed Inference, 1.31s elapsed\n",
      "Current Global Offset: 0.0270mas\n",
      "Number of Training Data: 44536, Number of Validation Data: 4948\n",
      "Epoch 1/1\n",
      " - 10s - loss: -2.8612e+00 - output_loss: -2.8612e+00 - variance_output_loss: -2.8612e+00 - output_mean_absolute_error: 0.0529 - output_mean_error: -1.7474e-04 - val_loss: -2.8592e+00 - val_output_loss: -2.8592e+00 - val_variance_output_loss: -2.8592e+00 - val_output_mean_absolute_error: 0.0524 - val_output_mean_error: -3.5807e-03\n",
      "Completed Training, 11.04s in total\n",
      "Starting Dropout Variational Inference\n",
      "Completed Dropout Variational Inference with 10 forward passes, 19.26s elapsed\n",
      "Number of Training Data: 44536, Number of Validation Data: 4948\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.7966 - mean_absolute_error: 0.1608 - mean_error: 0.0272 - val_loss: 0.1935 - val_mean_absolute_error: 0.1460 - val_mean_error: 0.0167\n",
      "Completed Training, 1.99s in total\n",
      "===========================================\n",
      "Starting Inference\n",
      "Completed Inference, 0.97s elapsed\n",
      "Current Global Offset: 0.0384mas\n",
      "Number of Training Data: 44536, Number of Validation Data: 4948\n",
      "Epoch 1/1\n",
      " - 10s - loss: -2.8536e+00 - output_loss: -2.8536e+00 - variance_output_loss: -2.8536e+00 - output_mean_absolute_error: 0.0530 - output_mean_error: 1.4786e-04 - val_loss: -2.8300e+00 - val_output_loss: -2.8300e+00 - val_variance_output_loss: -2.8300e+00 - val_output_mean_absolute_error: 0.0545 - val_output_mean_error: -2.0395e-04\n",
      "Completed Training, 11.01s in total\n",
      "Starting Dropout Variational Inference\n",
      "Completed Dropout Variational Inference with 10 forward passes, 19.30s elapsed\n",
      "Number of Training Data: 44536, Number of Validation Data: 4948\n",
      "Epoch 1/1\n",
      " - 2s - loss: 0.7500 - mean_absolute_error: 0.1598 - mean_error: 0.0126 - val_loss: 0.1520 - val_mean_absolute_error: 0.1475 - val_mean_error: 0.0052\n",
      "Completed Training, 2.04s in total\n",
      "===========================================\n",
      "Starting Inference\n",
      "Completed Inference, 1.06s elapsed\n",
      "Current Global Offset: 0.0426mas\n",
      "Number of Training Data: 44536, Number of Validation Data: 4948\n",
      "Epoch 1/1\n",
      " - 11s - loss: -2.8649e+00 - output_loss: -2.8649e+00 - variance_output_loss: -2.8649e+00 - output_mean_absolute_error: 0.0524 - output_mean_error: 1.7677e-04 - val_loss: -2.8339e+00 - val_output_loss: -2.8339e+00 - val_variance_output_loss: -2.8339e+00 - val_output_mean_absolute_error: 0.0542 - val_output_mean_error: -2.4084e-03\n",
      "Completed Training, 11.03s in total\n",
      "Starting Dropout Variational Inference\n",
      "Completed Dropout Variational Inference with 10 forward passes, 19.25s elapsed\n",
      "Number of Training Data: 44536, Number of Validation Data: 4948\n",
      "Epoch 1/1\n",
      " - 2s - loss: 0.7327 - mean_absolute_error: 0.1587 - mean_error: 0.0166 - val_loss: 0.1783 - val_mean_absolute_error: 0.1450 - val_mean_error: 0.0057\n",
      "Completed Training, 2.04s in total\n",
      "===========================================\n",
      "Starting Inference\n",
      "Completed Inference, 1.16s elapsed\n",
      "Current Global Offset: 0.0477mas\n",
      "Number of Training Data: 44536, Number of Validation Data: 4948\n",
      "Epoch 1/1\n",
      " - 10s - loss: -2.8708e+00 - output_loss: -2.8708e+00 - variance_output_loss: -2.8708e+00 - output_mean_absolute_error: 0.0521 - output_mean_error: -1.7426e-04 - val_loss: -2.8489e+00 - val_output_loss: -2.8489e+00 - val_variance_output_loss: -2.8489e+00 - val_output_mean_absolute_error: 0.0528 - val_output_mean_error: 0.0089\n",
      "Completed Training, 11.02s in total\n",
      "Starting Dropout Variational Inference\n",
      "Completed Dropout Variational Inference with 10 forward passes, 19.25s elapsed\n",
      "Number of Training Data: 44536, Number of Validation Data: 4948\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.6825 - mean_absolute_error: 0.1603 - mean_error: -7.8665e-03 - val_loss: 0.2229 - val_mean_absolute_error: 0.1586 - val_mean_error: -1.5839e-02\n",
      "Completed Training, 1.98s in total\n",
      "===========================================\n",
      "Starting Inference\n",
      "Completed Inference, 1.04s elapsed\n",
      "Current Global Offset: 0.0450mas\n",
      "Number of Training Data: 44536, Number of Validation Data: 4948\n",
      "Epoch 1/1\n",
      " - 10s - loss: -2.8703e+00 - output_loss: -2.8703e+00 - variance_output_loss: -2.8703e+00 - output_mean_absolute_error: 0.0517 - output_mean_error: 5.6180e-04 - val_loss: -2.8852e+00 - val_output_loss: -2.8852e+00 - val_variance_output_loss: -2.8852e+00 - val_output_mean_absolute_error: 0.0523 - val_output_mean_error: 0.0017\n",
      "Completed Training, 11.02s in total\n",
      "Starting Dropout Variational Inference\n",
      "Completed Dropout Variational Inference with 10 forward passes, 19.24s elapsed\n",
      "Number of Training Data: 44536, Number of Validation Data: 4948\n",
      "Epoch 1/1\n",
      " - 2s - loss: 0.7082 - mean_absolute_error: 0.1582 - mean_error: 0.0048 - val_loss: 0.2316 - val_mean_absolute_error: 0.1593 - val_mean_error: 0.0103\n",
      "Completed Training, 2.04s in total\n",
      "===========================================\n",
      "Starting Inference\n",
      "Completed Inference, 0.98s elapsed\n",
      "Current Global Offset: 0.0463mas\n",
      "Number of Training Data: 44536, Number of Validation Data: 4948\n",
      "Epoch 1/1\n",
      " - 11s - loss: -2.8817e+00 - output_loss: -2.8817e+00 - variance_output_loss: -2.8817e+00 - output_mean_absolute_error: 0.0518 - output_mean_error: 8.0393e-04 - val_loss: -2.8987e+00 - val_output_loss: -2.8987e+00 - val_variance_output_loss: -2.8987e+00 - val_output_mean_absolute_error: 0.0507 - val_output_mean_error: 1.2971e-04\n",
      "Completed Training, 11.02s in total\n",
      "Starting Dropout Variational Inference\n",
      "Completed Dropout Variational Inference with 10 forward passes, 19.27s elapsed\n",
      "Number of Training Data: 44536, Number of Validation Data: 4948\n",
      "Epoch 1/1\n",
      " - 2s - loss: 0.6649 - mean_absolute_error: 0.1552 - mean_error: 0.0127 - val_loss: 0.2932 - val_mean_absolute_error: 0.1561 - val_mean_error: 0.0148\n",
      "Completed Training, 2.57s in total\n",
      "===========================================\n",
      "Starting Inference\n",
      "Completed Inference, 1.13s elapsed\n",
      "Current Global Offset: 0.0483mas\n",
      "Number of Training Data: 44536, Number of Validation Data: 4948\n",
      "Epoch 1/1\n",
      " - 10s - loss: -2.8830e+00 - output_loss: -2.8830e+00 - variance_output_loss: -2.8830e+00 - output_mean_absolute_error: 0.0512 - output_mean_error: 4.5497e-04 - val_loss: -2.8689e+00 - val_output_loss: -2.8689e+00 - val_variance_output_loss: -2.8689e+00 - val_output_mean_absolute_error: 0.0517 - val_output_mean_error: 0.0047\n",
      "Completed Training, 11.04s in total\n",
      "Starting Dropout Variational Inference\n",
      "Completed Dropout Variational Inference with 10 forward passes, 19.38s elapsed\n",
      "Number of Training Data: 44536, Number of Validation Data: 4948\n",
      "Epoch 1/1\n",
      " - 2s - loss: 1.0873 - mean_absolute_error: 0.1601 - mean_error: 0.0094 - val_loss: 0.1345 - val_mean_absolute_error: 0.1496 - val_mean_error: 0.0064\n",
      "Completed Training, 2.04s in total\n",
      "===========================================\n",
      "Starting Inference\n",
      "Completed Inference, 1.07s elapsed\n",
      "Current Global Offset: 0.0498mas\n",
      "Number of Training Data: 44536, Number of Validation Data: 4948\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      " - 10s - loss: -2.8854e+00 - output_loss: -2.8854e+00 - variance_output_loss: -2.8854e+00 - output_mean_absolute_error: 0.0518 - output_mean_error: 5.9763e-04 - val_loss: -2.9007e+00 - val_output_loss: -2.9007e+00 - val_variance_output_loss: -2.9007e+00 - val_output_mean_absolute_error: 0.0511 - val_output_mean_error: 0.0058\n",
      "Completed Training, 10.95s in total\n",
      "Starting Dropout Variational Inference\n",
      "Completed Dropout Variational Inference with 10 forward passes, 19.23s elapsed\n",
      "Number of Training Data: 44536, Number of Validation Data: 4948\n",
      "Epoch 1/1\n",
      " - 2s - loss: 0.6611 - mean_absolute_error: 0.1571 - mean_error: 0.0040 - val_loss: 0.4562 - val_mean_absolute_error: 0.1677 - val_mean_error: 0.0064\n",
      "Completed Training, 2.04s in total\n",
      "===========================================\n",
      "Starting Inference\n",
      "Completed Inference, 1.24s elapsed\n",
      "Current Global Offset: 0.0503mas\n",
      "Number of Training Data: 44536, Number of Validation Data: 4948\n",
      "Epoch 1/1\n",
      " - 10s - loss: -2.8911e+00 - output_loss: -2.8912e+00 - variance_output_loss: -2.8912e+00 - output_mean_absolute_error: 0.0515 - output_mean_error: 5.3157e-04 - val_loss: -2.8384e+00 - val_output_loss: -2.8384e+00 - val_variance_output_loss: -2.8384e+00 - val_output_mean_absolute_error: 0.0555 - val_output_mean_error: -1.1000e-03\n",
      "Completed Training, 10.97s in total\n",
      "Starting Dropout Variational Inference\n",
      "Completed Dropout Variational Inference with 10 forward passes, 19.25s elapsed\n",
      "Number of Training Data: 44536, Number of Validation Data: 4948\n",
      "Epoch 1/1\n",
      " - 2s - loss: 0.2815 - mean_absolute_error: 0.1487 - mean_error: 0.0079 - val_loss: 3.8416 - val_mean_absolute_error: 0.1979 - val_mean_error: 0.0417\n",
      "Completed Training, 2.09s in total\n",
      "===========================================\n",
      "Starting Inference\n",
      "Completed Inference, 1.25s elapsed\n",
      "Current Global Offset: 0.0517mas\n",
      "Number of Training Data: 44536, Number of Validation Data: 4948\n",
      "Epoch 1/1\n",
      " - 11s - loss: -2.8831e+00 - output_loss: -2.8832e+00 - variance_output_loss: -2.8832e+00 - output_mean_absolute_error: 0.0515 - output_mean_error: 4.8381e-04 - val_loss: -2.9023e+00 - val_output_loss: -2.9023e+00 - val_variance_output_loss: -2.9023e+00 - val_output_mean_absolute_error: 0.0539 - val_output_mean_error: 0.0070\n",
      "Completed Training, 11.32s in total\n",
      "Starting Dropout Variational Inference\n",
      "Completed Dropout Variational Inference with 10 forward passes, 19.77s elapsed\n",
      "Number of Training Data: 44536, Number of Validation Data: 4948\n",
      "Epoch 1/1\n",
      " - 2s - loss: 0.6426 - mean_absolute_error: 0.1576 - mean_error: -7.2098e-04 - val_loss: 0.2852 - val_mean_absolute_error: 0.1645 - val_mean_error: 0.0061\n",
      "Completed Training, 2.09s in total\n",
      "===========================================\n",
      "Starting Inference\n",
      "Completed Inference, 1.01s elapsed\n",
      "Current Global Offset: 0.0514mas\n",
      "Number of Training Data: 44536, Number of Validation Data: 4948\n",
      "Epoch 1/1\n",
      " - 10s - loss: -2.8912e+00 - output_loss: -2.8912e+00 - variance_output_loss: -2.8912e+00 - output_mean_absolute_error: 0.0506 - output_mean_error: 6.9555e-04 - val_loss: -2.8820e+00 - val_output_loss: -2.8820e+00 - val_variance_output_loss: -2.8820e+00 - val_output_mean_absolute_error: 0.0508 - val_output_mean_error: -9.9627e-04\n",
      "Completed Training, 11.01s in total\n",
      "Starting Dropout Variational Inference\n",
      "Completed Dropout Variational Inference with 10 forward passes, 19.33s elapsed\n",
      "Number of Training Data: 44536, Number of Validation Data: 4948\n",
      "Epoch 1/1\n",
      " - 2s - loss: 1.1652 - mean_absolute_error: 0.1571 - mean_error: 0.0214 - val_loss: 0.0988 - val_mean_absolute_error: 0.1387 - val_mean_error: -6.7675e-03\n",
      "Completed Training, 2.04s in total\n",
      "===========================================\n",
      "Starting Inference\n",
      "Completed Inference, 1.38s elapsed\n",
      "Current Global Offset: 0.0560mas\n",
      "Number of Training Data: 44536, Number of Validation Data: 4948\n",
      "Epoch 1/1\n",
      " - 10s - loss: -2.8910e+00 - output_loss: -2.8910e+00 - variance_output_loss: -2.8910e+00 - output_mean_absolute_error: 0.0511 - output_mean_error: 4.4592e-04 - val_loss: -2.9374e+00 - val_output_loss: -2.9374e+00 - val_variance_output_loss: -2.9374e+00 - val_output_mean_absolute_error: 0.0486 - val_output_mean_error: 0.0015\n",
      "Completed Training, 11.03s in total\n",
      "Starting Dropout Variational Inference\n",
      "Completed Dropout Variational Inference with 10 forward passes, 19.35s elapsed\n",
      "Number of Training Data: 44536, Number of Validation Data: 4948\n",
      "Epoch 1/1\n",
      " - 2s - loss: 0.6646 - mean_absolute_error: 0.1528 - mean_error: 0.0147 - val_loss: 0.1446 - val_mean_absolute_error: 0.1458 - val_mean_error: 6.6975e-04\n",
      "Completed Training, 2.04s in total\n",
      "===========================================\n",
      "Starting Inference\n",
      "Completed Inference, 1.00s elapsed\n",
      "Current Global Offset: 0.0561mas\n",
      "Number of Training Data: 44536, Number of Validation Data: 4948\n",
      "Epoch 1/1\n",
      " - 10s - loss: -2.8876e+00 - output_loss: -2.8876e+00 - variance_output_loss: -2.8876e+00 - output_mean_absolute_error: 0.0514 - output_mean_error: 6.7239e-04 - val_loss: -2.9438e+00 - val_output_loss: -2.9438e+00 - val_variance_output_loss: -2.9438e+00 - val_output_mean_absolute_error: 0.0482 - val_output_mean_error: -2.0053e-03\n",
      "Completed Training, 10.96s in total\n",
      "Starting Dropout Variational Inference\n",
      "Completed Dropout Variational Inference with 10 forward passes, 19.33s elapsed\n",
      "Number of Training Data: 44536, Number of Validation Data: 4948\n",
      "Epoch 1/1\n",
      " - 2s - loss: 0.6448 - mean_absolute_error: 0.1500 - mean_error: 0.0169 - val_loss: 0.3137 - val_mean_absolute_error: 0.1595 - val_mean_error: 0.0294\n",
      "Completed Training, 2.04s in total\n",
      "===========================================\n",
      "Starting Inference\n",
      "Completed Inference, 1.10s elapsed\n",
      "Current Global Offset: 0.0562mas\n",
      "Number of Training Data: 44536, Number of Validation Data: 4948\n",
      "Epoch 1/1\n",
      " - 11s - loss: -2.9014e+00 - output_loss: -2.9014e+00 - variance_output_loss: -2.9014e+00 - output_mean_absolute_error: 0.0507 - output_mean_error: 6.1220e-04 - val_loss: -2.8872e+00 - val_output_loss: -2.8873e+00 - val_variance_output_loss: -2.8873e+00 - val_output_mean_absolute_error: 0.0488 - val_output_mean_error: 0.0035\n",
      "Completed Training, 11.10s in total\n",
      "Starting Dropout Variational Inference\n",
      "Completed Dropout Variational Inference with 10 forward passes, 19.41s elapsed\n",
      "Number of Training Data: 44536, Number of Validation Data: 4948\n",
      "Epoch 1/1\n",
      " - 2s - loss: 0.7426 - mean_absolute_error: 0.1536 - mean_error: 0.0072 - val_loss: 0.1683 - val_mean_absolute_error: 0.1517 - val_mean_error: -4.5029e-03\n",
      "Completed Training, 2.04s in total\n",
      "model_weights.h5 saved to D:\\University\\AST425\\astroNN_gaia_dr2_paper\\astroNN_Ks_fakemag_adversial/model_weights.h5\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import keras.backend as K\n",
    "from tensorflow import Graph, Session\n",
    "from astroNN.gaia import gaiadr2_parallax, mag_to_fakemag, extinction_correction, fakemag_to_pc\n",
    "from astroNN.models import load_folder\n",
    "\n",
    "lr = 0.0001\n",
    "\n",
    "apogee_nn = load_folder(\"astroNN_Ks_fakemag\")\n",
    "with apogee_nn.graph.as_default():\n",
    "    with apogee_nn.session.as_default():\n",
    "        apogee_nn.max_epochs = 1\n",
    "        apogee_nn.mc_num = 10  # smaller mc feedforward pass for batter performance\n",
    "\n",
    "gaia_nn = load_folder(\"gaia_0deg_0823\")\n",
    "with gaia_nn.graph.as_default():\n",
    "    with gaia_nn.session.as_default():\n",
    "        gaia_nn.max_epochs = 1\n",
    "\n",
    "with h5py.File('gaia_dr2_train.h5') as F:  # ensure the file will be cleaned up\n",
    "    parallax = np.array(F['parallax'])\n",
    "    # only train on star further than 0.1kpc away\n",
    "    far_away = [parallax<10.]\n",
    "    parallax = parallax[far_away]\n",
    "    parallax_error = np.array(F['parallax_err'])[far_away]\n",
    "    spectra = np.array(F['spectra'])[far_away]\n",
    "    Kcorr = np.array(F['corrected_K'])[far_away]\n",
    "    \n",
    "\n",
    "counter = 0\n",
    "\n",
    "for epoch in range(15):\n",
    "    with apogee_nn.graph.as_default():\n",
    "        with apogee_nn.session.as_default():\n",
    "            K.set_value(apogee_nn.keras_model.optimizer.lr, lr)\n",
    "\n",
    "    with gaia_nn.graph.as_default():\n",
    "        with gaia_nn.session.as_default():\n",
    "            K.set_value(gaia_nn.keras_model.optimizer.lr, lr/2)\n",
    "            \n",
    "    counter += 1\n",
    "    if counter > 5:\n",
    "        # schedule learning rate decay manually\n",
    "        lr /= 2\n",
    "        counter = 0  # reset coutner\n",
    "    \n",
    "    print(\"===========================================\")\n",
    "    with gaia_nn.graph.as_default():\n",
    "        with gaia_nn.session.as_default():\n",
    "            parallax_gen = gaia_nn.test(np.expand_dims(parallax, axis=1))\n",
    "            print(f\"Current Global Offset: {gaia_nn.get_weights()[0][0][0][0]:.{4}f}mas\")\n",
    "    fakemag_gen, fakemag_gen_err = mag_to_fakemag(Kcorr, parallax_gen[:, 0], parallax_error)\n",
    "\n",
    "    # Train the discriminator\n",
    "    with apogee_nn.graph.as_default():\n",
    "        with apogee_nn.session.as_default():\n",
    "            d_loss_real = apogee_nn.train(spectra, fakemag_gen, labels_err=fakemag_gen_err)\n",
    "            fake_gen, fake_gen_err = apogee_nn.test(spectra)\n",
    "    para_teach, para_teach_err = fakemag_to_pc(fake_gen[:, 0], Kcorr, fake_gen_err['total'][:, 0])\n",
    "    para_teach, para_teach_err = 1000 / para_teach.value, 1000 / para_teach_err.value\n",
    "\n",
    "    # Train the generator (to have the discriminator label samples as valid)\n",
    "    with gaia_nn.graph.as_default():\n",
    "        with gaia_nn.session.as_default():\n",
    "            g_loss = gaia_nn.train(parallax, para_teach)\n",
    "\n",
    "# saving model\n",
    "with apogee_nn.graph.as_default():\n",
    "    with apogee_nn.session.as_default():\n",
    "        apogee_nn.save(\"astroNN_Ks_fakemag_adversial\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
